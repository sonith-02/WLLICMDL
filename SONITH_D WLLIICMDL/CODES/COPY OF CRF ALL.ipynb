{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM8q9UgRsH2VqIregP1Aq+A"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["UPDATED"],"metadata":{"id":"x6tRWeGA3CeO"}},{"cell_type":"code","source":["\n","# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","!pip install sklearn_crfsuite\n","\n","import pandas as pd\n","import os\n","import numpy as np\n","import string\n","from sklearn_crfsuite import CRF\n","from sklearn_crfsuite import metrics\n","from sklearn.model_selection import train_test_split\n","\n","# Define function to read and format data from CSV files\n","def read_and_format_csv(file_path):\n","    sents = []\n","    sent = []\n","\n","    # Read the CSV file into a DataFrame\n","    data = pd.read_csv(file_path)\n","\n","    # Assuming the CSV has two columns: 'Word' and 'Tag'\n","    for _, row in data.iterrows():\n","        word = row['Word']\n","        tag = row['Tag']\n","\n","        # Check if the word and tag are valid (not NaN or None)\n","        if pd.isna(word) or pd.isna(tag):\n","            continue\n","\n","        # Check if word is '.' to signify the end of a sentence\n","        if word == '.':\n","            if sent:\n","                sents.append(sent)\n","                sent = []\n","        else:\n","            sent.append((str(word), str(tag)))  # Ensure word and tag are strings\n","\n","    # Append the last sentence if it exists\n","    if sent:\n","        sents.append(sent)\n","\n","    return sents\n","\n","\n","# Feature extraction functions\n","def word2features(sent, i):\n","    word = sent[i][0]\n","    features = {\n","        'bias': 1.0,\n","        'word': word,\n","        'len(word)': len(word),\n","        'word[:4]': word[:4],\n","        'word[:3]': word[:3],\n","        'word[:2]': word[:2],\n","        'word[-3:]': word[-3:],\n","        'word[-2:]': word[-2:],\n","        'word[-4:]': word[-4:],\n","        'word.ispunctuation': word in string.punctuation,\n","        'word.isdigit()': word.isdigit(),\n","    }\n","    if i > 0:\n","        word1l = sent[i-1][0]\n","        features.update({\n","            '-1:word': word1l,\n","            '-1:len(word)': len(word1l),\n","            '-1:word[:3]': word1l[:3],\n","            '-1:word[:2]': word1l[:2],\n","            '-1:word[-3:]': word1l[-3:],\n","            '-1:word[-2:]': word1l[-2:],\n","            '-1:word.isdigit()': word1l.isdigit(),\n","            '-1:word.ispunctuation': word1l in string.punctuation,\n","        })\n","    else:\n","        features['BOS'] = True\n","\n","    if i > 1:\n","        word2l = sent[i-2][0]\n","        features.update({\n","            '-2:word': word2l,\n","            '-2:len(word)': len(word2l),\n","            '-2:word[:3]': word2l[:3],\n","            '-2:word[:2]': word2l[:2],\n","            '-2:word[-3:]': word2l[-3:],\n","            '-2:word[-2:]': word2l[-2:],\n","            '-2:word.isdigit()': word2l.isdigit(),\n","            '-2:word.ispunctuation': word2l in string.punctuation,\n","        })\n","\n","    if i < len(sent) - 1:\n","        word1r = sent[i+1][0]\n","        features.update({\n","            '+1:word': word1r,\n","            '+1:len(word)': len(word1r),\n","            '+1:word[:3]': word1r[:3],\n","            '+1:word[:2]': word1r[:2],\n","            '+1:word[-3:]': word1r[-3:],\n","            '+1:word[-2:]': word1r[-2:],\n","            '+1:word.isdigit()': word1r.isdigit(),\n","            '+1:word.ispunctuation': word1r in string.punctuation,\n","        })\n","    else:\n","        features['EOS'] = True\n","\n","    if i < len(sent) - 2:\n","        word2r = sent[i+2][0]\n","        features.update({\n","            '+2:word': word2r,\n","            '+2:len(word)': len(word2r),\n","            '+2:word[:3]': word2r[:3],\n","            '+2:word[:2]': word2r[:2],\n","            '+2:word[-3:]': word2r[-3:],\n","            '+2:word[-2:]': word2r[-2:],\n","            '+2:word.isdigit()': word2r.isdigit(),\n","            '+2:word.ispunctuation': word2r in string.punctuation,\n","        })\n","\n","    return features\n","\n","def sent2features(sent):\n","    return [word2features(sent, i) for i in range(len(sent))]\n","\n","def sent2labels(sent):\n","    return [word[1] for word in sent]\n","\n","\n","# Updated datasets with correct file paths\n","datasets = {\n","    \"Tamil\": {\n","        \"train\": \"/content/drive/MyDrive/DATASET/all language correct format dataset /correct_tamil_dataset.csv\",\n","        \"validation\": \"/content/drive/MyDrive/DATASET/all language correct format dataset /correct_tamil_validation\"\n","    },\n","    \"Malayalam\": {\n","        \"train\": \"/content/drive/MyDrive/DATASET/all language correct format dataset /Final_mal_train(80%)  (1).csv\",\n","        \"validation\": \"/content/drive/MyDrive/DATASET/all language correct format dataset /Final_mal_dev(20%) (1).csv\"\n","    },\n","    \"Tulu\": {\n","        \"train\": \"/content/drive/MyDrive/DATASET/all language correct format dataset /correct_tulu_train_set\",\n","        \"validation\": \"/content/drive/MyDrive/DATASET/all language correct format dataset /correct_tulu_validation_set\"\n","    },\n","    \"Kannada\": {\n","        \"train\": \"/content/drive/MyDrive/DATASET/all language correct format dataset /correct_kannada_train\",\n","        \"validation\": \"/content/drive/MyDrive/DATASET/all language correct format dataset /correct_kannada_validation\"\n","    }\n","}\n","\n","for language, paths in datasets.items():\n","    print(f\"\\nProcessing {language} dataset...\")\n","\n","    # Check if the file paths exist\n","    if not os.path.exists(paths['train']) or not os.path.exists(paths['validation']):\n","        print(f\"File paths for {language} dataset are incorrect or files do not exist.\")\n","        continue\n","\n","    try:\n","        # Read and format the data using the CSV-specific function\n","        train_sents = read_and_format_csv(paths['train'])\n","        test_sents = read_and_format_csv(paths['validation'])\n","\n","        # Check if the datasets are loaded properly\n","        if not train_sents or not test_sents:\n","            print(f\"Failed to load data for {language}. Check the data format.\")\n","            continue\n","\n","        # Prepare features and labels for training and testing\n","        X_train = [sent2features(s) for s in train_sents]\n","        y_train = [sent2labels(s) for s in train_sents]\n","        X_test = [sent2features(s) for s in test_sents]\n","        y_test = [sent2labels(s) for s in test_sents]\n","\n","        # Train CRF model\n","        crf = CRF(\n","            algorithm='lbfgs',\n","            c1=0.1,\n","            c2=0.1,\n","            max_iterations=100,\n","            all_possible_transitions=True\n","        )\n","        crf.fit(X_train, y_train)\n","\n","        # Predict and evaluate\n","        predictions = crf.predict(X_test)\n","\n","        # Determine number of labels for each language\n","        if language in ['Malayalam', 'Tulu']:\n","            num_labels = 8  # 8 labels for Malayalam and Tulu\n","        else:\n","            num_labels = 7  # 7 labels for Kannada and Tamil\n","\n","        print(f'F1 score on the test set for {language} = {metrics.flat_f1_score(y_test, predictions, average=\"weighted\"):.4f}')\n","        print(f'Accuracy on the test set for {language} = {metrics.flat_accuracy_score(y_test, predictions):.4f}')\n","\n","    except Exception as e:\n","        print(f\"An error occurred while processing the {language} dataset: {str(e)}\")\n"],"metadata":{"id":"H_gj4EgF3Dt9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1723962009337,"user_tz":-330,"elapsed":55092,"user":{"displayName":"WLLIIDL","userId":"09959969093315429850"}},"outputId":"cbe14be3-e49a-417c-bd02-aa2a72ad65ef"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Requirement already satisfied: sklearn_crfsuite in /usr/local/lib/python3.10/dist-packages (0.5.0)\n","Requirement already satisfied: python-crfsuite>=0.9.7 in /usr/local/lib/python3.10/dist-packages (from sklearn_crfsuite) (0.9.10)\n","Requirement already satisfied: scikit-learn>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from sklearn_crfsuite) (1.3.2)\n","Requirement already satisfied: tabulate>=0.4.2 in /usr/local/lib/python3.10/dist-packages (from sklearn_crfsuite) (0.9.0)\n","Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.10/dist-packages (from sklearn_crfsuite) (4.66.5)\n","Requirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.0->sklearn_crfsuite) (1.26.4)\n","Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.0->sklearn_crfsuite) (1.13.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.0->sklearn_crfsuite) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.0->sklearn_crfsuite) (3.5.0)\n","\n","Processing Tamil dataset...\n","F1 score on the test set for Tamil = 0.8952\n","Accuracy on the test set for Tamil = 0.8962\n","\n","Processing Malayalam dataset...\n","F1 score on the test set for Malayalam = 0.8628\n","Accuracy on the test set for Malayalam = 0.8647\n","\n","Processing Tulu dataset...\n","F1 score on the test set for Tulu = 0.8670\n","Accuracy on the test set for Tulu = 0.8704\n","\n","Processing Kannada dataset...\n","F1 score on the test set for Kannada = 0.9426\n","Accuracy on the test set for Kannada = 0.9436\n"]}]},{"cell_type":"code","source":["# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","!pip install sklearn_crfsuite\n","\n","import pandas as pd\n","import os\n","import numpy as np\n","import string\n","from sklearn_crfsuite import CRF\n","from sklearn_crfsuite import metrics\n","from sklearn.model_selection import train_test_split\n","\n","# Define function to read and format data from CSV files\n","def read_and_format_csv(file_path):\n","    sents = []\n","    sent = []\n","\n","    # Read the CSV file into a DataFrame\n","    data = pd.read_csv(file_path)\n","\n","    # Assuming the CSV has two columns: 'Word' and 'Tag'\n","    for _, row in data.iterrows():\n","        word = row['Word']\n","        tag = row['Tag']\n","\n","        # Check if the word and tag are valid (not NaN or None)\n","        if pd.isna(word) or pd.isna(tag):\n","            continue\n","\n","        # Check if word is '.' to signify the end of a sentence\n","        if word == '.':\n","            if sent:\n","                sents.append(sent)\n","                sent = []\n","        else:\n","            sent.append((str(word), str(tag)))  # Ensure word and tag are strings\n","\n","    # Append the last sentence if it exists\n","    if sent:\n","        sents.append(sent)\n","\n","    return sents\n","\n","# Feature extraction functions\n","def word2features(sent, i):\n","    word = sent[i][0]\n","    features = {\n","        'bias': 1.0,\n","        'word': word,\n","        'len(word)': len(word),\n","        'word[:4]': word[:4],\n","        'word[:3]': word[:3],\n","        'word[:2]': word[:2],\n","        'word[-3:]': word[-3:],\n","        'word[-2:]': word[-2:],\n","        'word[-4:]': word[-4:],\n","        'word.ispunctuation': word in string.punctuation,\n","        'word.isdigit()': word.isdigit(),\n","    }\n","    if i > 0:\n","        word1l = sent[i-1][0]\n","        features.update({\n","            '-1:word': word1l,\n","            '-1:len(word)': len(word1l),\n","            '-1:word[:3]': word1l[:3],\n","            '-1:word[:2]': word1l[:2],\n","            '-1:word[-3:]': word1l[-3:],\n","            '-1:word[-2:]': word1l[-2:],\n","            '-1:word.isdigit()': word1l.isdigit(),\n","            '-1:word.ispunctuation': word1l in string.punctuation,\n","        })\n","    else:\n","        features['BOS'] = True\n","\n","    if i > 1:\n","        word2l = sent[i-2][0]\n","        features.update({\n","            '-2:word': word2l,\n","            '-2:len(word)': len(word2l),\n","            '-2:word[:3]': word2l[:3],\n","            '-2:word[:2]': word2l[:2],\n","            '-2:word[-3:]': word2l[-3:],\n","            '-2:word[-2:]': word2l[-2:],\n","            '-2:word.isdigit()': word2l.isdigit(),\n","            '-2:word.ispunctuation': word2l in string.punctuation,\n","        })\n","\n","    if i < len(sent) - 1:\n","        word1r = sent[i+1][0]\n","        features.update({\n","            '+1:word': word1r,\n","            '+1:len(word)': len(word1r),\n","            '+1:word[:3]': word1r[:3],\n","            '+1:word[:2]': word1r[:2],\n","            '+1:word[-3:]': word1r[-3:],\n","            '+1:word[-2:]': word1r[-2:],\n","            '+1:word.isdigit()': word1r.isdigit(),\n","            '+1:word.ispunctuation': word1r in string.punctuation,\n","        })\n","    else:\n","        features['EOS'] = True\n","\n","    if i < len(sent) - 2:\n","        word2r = sent[i+2][0]\n","        features.update({\n","            '+2:word': word2r,\n","            '+2:len(word)': len(word2r),\n","            '+2:word[:3]': word2r[:3],\n","            '+2:word[:2]': word2r[:2],\n","            '+2:word[-3:]': word2r[-3:],\n","            '+2:word[-2:]': word2r[-2:],\n","            '+2:word.isdigit()': word2r.isdigit(),\n","            '+2:word.ispunctuation': word2r in string.punctuation,\n","        })\n","\n","    return features\n","\n","def sent2features(sent):\n","    return [word2features(sent, i) for i in range(len(sent))]\n","\n","def sent2labels(sent):\n","    return [word[1] for word in sent]\n","\n","# Updated datasets with correct file paths\n","datasets = {\n","    \"Tamil\": {\n","        \"train\": \"/content/drive/MyDrive/DATASET/all language correct format dataset /correct_tamil_dataset.csv\",\n","        \"validation\": \"/content/drive/MyDrive/DATASET/all language correct format dataset /correct_tamil_validation\"\n","    },\n","    \"Malayalam\": {\n","        \"train\": \"/content/drive/MyDrive/DATASET/all language correct format dataset /Final_mal_train(80%)  (1).csv\",\n","        \"validation\": \"/content/drive/MyDrive/DATASET/all language correct format dataset /Final_mal_dev(20%) (1).csv\"\n","    },\n","    \"Tulu\": {\n","        \"train\": \"/content/drive/MyDrive/DATASET/all language correct format dataset /correct_tulu_train_set\",\n","        \"validation\": \"/content/drive/MyDrive/DATASET/all language correct format dataset /correct_tulu_validation_set\"\n","    },\n","    \"Kannada\": {\n","        \"train\": \"/content/drive/MyDrive/DATASET/all language correct format dataset /correct_kannada_train\",\n","        \"validation\": \"/content/drive/MyDrive/DATASET/all language correct format dataset /correct_kannada_validation\"\n","    }\n","}\n","\n","for language, paths in datasets.items():\n","    print(f\"\\nProcessing {language} dataset...\")\n","\n","    # Check if the file paths exist\n","    if not os.path.exists(paths['train']) or not os.path.exists(paths['validation']):\n","        print(f\"File paths for {language} dataset are incorrect or files do not exist.\")\n","        continue\n","\n","    try:\n","        # Read and format the data using the CSV-specific function\n","        train_sents = read_and_format_csv(paths['train'])\n","        test_sents = read_and_format_csv(paths['validation'])\n","\n","        # Check if the datasets are loaded properly\n","        if not train_sents or not test_sents:\n","            print(f\"Failed to load data for {language}. Check the data format.\")\n","            continue\n","\n","        # Prepare features and labels for training and testing\n","        X_train = [sent2features(s) for s in train_sents]\n","        y_train = [sent2labels(s) for s in train_sents]\n","        X_test = [sent2features(s) for s in test_sents]\n","        y_test = [sent2labels(s) for s in test_sents]\n","\n","        # Train CRF model\n","        crf = CRF(\n","            algorithm='lbfgs',\n","            c1=0.1,\n","            c2=0.1,\n","            max_iterations=100,\n","            all_possible_transitions=True\n","        )\n","        crf.fit(X_train, y_train)\n","\n","        # Predict and evaluate\n","        predictions = crf.predict(X_test)\n","\n","        print(f'F1 score on the test set for {language} = {metrics.flat_f1_score(y_test, predictions, average=\"weighted\"):.4f}')\n","        print(f'Accuracy on the test set for {language} = {metrics.flat_accuracy_score(y_test, predictions):.4f}')\n","\n","        # Generate a classification report\n","        report = metrics.flat_classification_report(y_test, predictions, digits=3)\n","        print(f\"Classification report for {language}:\\n{report}\")\n","\n","    except Exception as e:\n","        print(f\"An error occurred while processing the {language} dataset: {str(e)}\")\n"],"metadata":{"id":"ntWaX3oGIJX-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724091822734,"user_tz":-330,"elapsed":98430,"user":{"displayName":"WLLIIDL","userId":"09959969093315429850"}},"outputId":"7fd7db46-1be5-448f-ac36-50713199fa54"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Collecting sklearn_crfsuite\n","  Downloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl.metadata (4.9 kB)\n","Collecting python-crfsuite>=0.9.7 (from sklearn_crfsuite)\n","  Downloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n","Requirement already satisfied: scikit-learn>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from sklearn_crfsuite) (1.3.2)\n","Requirement already satisfied: tabulate>=0.4.2 in /usr/local/lib/python3.10/dist-packages (from sklearn_crfsuite) (0.9.0)\n","Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.10/dist-packages (from sklearn_crfsuite) (4.66.5)\n","Requirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.0->sklearn_crfsuite) (1.26.4)\n","Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.0->sklearn_crfsuite) (1.13.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.0->sklearn_crfsuite) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.0->sklearn_crfsuite) (3.5.0)\n","Downloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl (10 kB)\n","Downloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: python-crfsuite, sklearn_crfsuite\n","Successfully installed python-crfsuite-0.9.10 sklearn_crfsuite-0.5.0\n","\n","Processing Tamil dataset...\n","F1 score on the test set for Tamil = 0.8952\n","Accuracy on the test set for Tamil = 0.8962\n","Classification report for Tamil:\n","              precision    recall  f1-score   support\n","\n","       Other      0.000     0.000     0.000         1\n","          en      0.919     0.887     0.903       496\n","        name      0.760     0.731     0.745       160\n","         sym      0.000     0.000     0.000         0\n","          tm      0.911     0.947     0.928      1000\n","        tmen      0.866     0.764     0.812       144\n","\n","    accuracy                          0.896      1801\n","   macro avg      0.576     0.555     0.565      1801\n","weighted avg      0.895     0.896     0.895      1801\n","\n","\n","Processing Malayalam dataset...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["F1 score on the test set for Malayalam = 0.8628\n","Accuracy on the test set for Malayalam = 0.8647\n","Classification report for Malayalam:\n","              precision    recall  f1-score   support\n","\n","     ENGLISH      0.928     0.881     0.904      2229\n","   MALAYALAM      0.921     0.952     0.936      4371\n","       MIXED      0.752     0.437     0.553       375\n","        NAME      0.633     0.796     0.705       504\n","      NUMBER      0.989     0.887     0.935       203\n","       OTHER      0.519     0.563     0.540       641\n","       PLACE      0.917     0.349     0.506        63\n","         SYM      0.000     0.000     0.000         2\n","\n","    accuracy                          0.865      8388\n","   macro avg      0.707     0.608     0.635      8388\n","weighted avg      0.869     0.865     0.863      8388\n","\n","\n","Processing Tulu dataset...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["F1 score on the test set for Tulu = 0.8670\n","Accuracy on the test set for Tulu = 0.8704\n","Classification report for Tulu:\n","              precision    recall  f1-score   support\n","\n","     English      0.938     0.916     0.927       742\n","     Kannada      0.738     0.692     0.715       273\n","    Location      0.917     0.805     0.857        41\n","       Mixed      0.871     0.474     0.614        57\n","        Name      0.830     0.689     0.753       135\n","       Other      0.768     0.624     0.688        85\n","        Tulu      0.866     0.938     0.901      1251\n","\n","    accuracy                          0.870      2584\n","   macro avg      0.847     0.734     0.779      2584\n","weighted avg      0.869     0.870     0.867      2584\n","\n","\n","Processing Kannada dataset...\n","F1 score on the test set for Kannada = 0.9426\n","Accuracy on the test set for Kannada = 0.9436\n","Classification report for Kannada:\n","              precision    recall  f1-score   support\n","\n","          en      0.959     0.985     0.972      1109\n","          kn      0.937     0.937     0.937       634\n","    location      1.000     0.615     0.762        13\n","       mixed      0.930     0.889     0.909       180\n","        name      0.993     0.924     0.957       158\n","       other      0.553     0.491     0.520        53\n","\n","    accuracy                          0.944      2147\n","   macro avg      0.895     0.807     0.843      2147\n","weighted avg      0.943     0.944     0.943      2147\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"qJaOjZG836fc"},"execution_count":null,"outputs":[]}]}